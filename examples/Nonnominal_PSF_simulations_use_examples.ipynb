{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Simulating Images with Nonnominal PSFs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout JWST OTE commissioning until about MIMF-3 (expected L+118 days), the JWST OTE will not be optimally aligned. The mirrors will be unstacked and unphased, especially for earlier commissioning activities, and thus the nominal JWST PSFs that MIRaGe uses for imaging simulations do not adequately represent the telescope state.\n",
    "\n",
    "### How to Simulate Images with Nonnominal PSFs\n",
    "In this notebook, we demonstrate how to simulate images with nonnominal PSFs (as will be the case during OTE commissioning) with MIRaGe. The process is as follows:\n",
    "- Using `webbpsf` or existing FITS files, generate PSF libraries from the desired mirror state for each observation/visit/exposure in a given observation\n",
    "- Generate MIRaGe YAML input files that include the directory where to find the special PSF libraries\n",
    "- Generate seed images from those YAMLs that use the appropriate PSF library for any given exposure\n",
    "- Follow the nominal procedures for adding dark exposure and detector effects\n",
    "\n",
    "### Table of Contents:\n",
    "1. [Export program information from APT](#export_apt)\n",
    "2. [Create diverse PSF library files](#create_psfs)\n",
    "3. [Create `.yaml` files for each exposure](#make_yamls)\n",
    "4. [Generate the simulated image](#simulate_images)\n",
    "\n",
    "Appendix 1: [Generating data for an entire observation](#simulate_whole_obs)\n",
    "\n",
    "Appendix 2: [Combining data into a mosaic](#mosaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Note:</b> <br>\n",
    "\n",
    "You must have installed the <code>mirage</code> package before running this notebook. Install it using the following command while in the <code>mirage</code> repository (where the <code>setup.py</code> file is located):<br><br>\n",
    "\n",
    "<code>pip install -e .</code>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "from glob import glob\n",
    "import os\n",
    "import pprint\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# Third Party Imports\n",
    "from astropy.io import fits\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pysiaf\n",
    "import webbpsf\n",
    "\n",
    "# Local Imports (from nircam_simulator package)\n",
    "from mirage import imaging_simulator\n",
    "from mirage.apt import apt_inputs\n",
    "from mirage.catalogs import get_catalog\n",
    "from mirage.yaml import yaml_generator\n",
    "\n",
    "# View matplotlib plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='export_apt'></a>\n",
    "# 1. Export APT files\n",
    "\n",
    "Open the APT file for the program you want to simulate. If you don't have the file locally, you can load this program in APT by selecting `File > Retrieve from STScI > Retrieve Using Proposal ID` and then entering the program ID (e.g. 1140). (You must be running APT in STScI mode for this retrieval method to be available.)\n",
    "\n",
    "Export the `.pointing` and `.xml` files for your given proposal in APT by selecting `File > Export...` and selecting both the xml and pointing file options. Save them in a place you will remember, naming them something descriptive such as `OTE06_1140.pointing`.\n",
    "\n",
    "For this example, we will simulate images from OTE-17: Image Stacking 2. In this stage of commissioning, the 18 mirror segments are being moved to transition from a hexagonal image array to 17 stacked segments with one kicked out. We will only look at observation 1, for brevity's sake. The neccessary files, `OTE17-1153-obs1only.pointing` and `OTE17-1153-obs1only.xml`, are located within the `examples/nonnominal_psf_data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_id = 1153\n",
    "\n",
    "# Where the pointing and XML file for this particular OTE CAR are located\n",
    "input_dir = './nonnominal_psf_data/'\n",
    "\n",
    "# Change the root if you named your files differently.\n",
    "root = 'OTE17-{}-obs1only'.format(prop_id)\n",
    "pointing_file = os.path.join(input_dir, '{}.pointing'.format(root))\n",
    "xml_file = os.path.join(input_dir, '{}.xml'.format(root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define location of output files\n",
    "\n",
    "The process of generating simulated images with MIRaGe produces a lot of files:\n",
    "- YAMLs carrying the OTE mirror state\n",
    "- FITS files of the segment PSF images\n",
    "- YAMLs carrying the specifications for simulations\n",
    "- FITS files of the simulated seed, dark, and compiled images\n",
    "\n",
    "We'll save those also in a local directory here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Where to save MIRaGe output\n",
    "out_dir = './nonnominal_psf_data/output/'\n",
    "\n",
    "# Where the segment PSF library files will be saved to (and read from!)\n",
    "library_dir = os.path.join(out_dir, 'gridded_psf_library')\n",
    "\n",
    "# Make sure both these directories exist\n",
    "for full_path in [out_dir, library_dir]:\n",
    "    if not os.path.exists(full_path):\n",
    "        os.makedirs(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='create_psfs'></a>\n",
    "# 2. Create unique, nonnominal PSF library files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We outline two methods here of using unique PSFs for each MIRaGe exposure:\n",
    "- If you have a list of **mirror moves/positions** describing different telescope states throughout the program, use [option 1](#adjustable_ote). We will use `webbpsf` to generate PSFs and then gridded PSF library objects from those telescope states.\n",
    "- If you have a list of pre-existing **FITS files** with PSFs from different telescope states throughout the program, use [option 2](#to_model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Segment Image Array (OTE-06)\n",
    "\n",
    "As mentioned above, we'll use the infrastructure of observation 1 in OTE-17: Image Stacking 2 (program 1153) for this example. \n",
    "\n",
    "This observation is a WFSC Commissioning observation that includes 17 Wavefront Control (WFC) groups to bring the mirrors in. (17 sets of image-mirror move-image plus 1 additional image.)\n",
    "\n",
    "So, in order to generate the YAML configuration files for program 1153 observation 1, MIRaGe will need 18  PSF paths. \n",
    "\n",
    "We can parse the `.pointing` file to verify that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the information from the pointing file\n",
    "apt_prop = apt_inputs.AptInput()\n",
    "pointing_tab = apt_prop.get_pointing_info(pointing_file, '1153')\n",
    "n_exposures = len(pointing_tab['visit_id'])\n",
    "print('MIRaGe requires PSF paths for {} exposures.'.format(len(pointing_tab['visit_id'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing PSF files\n",
    "\n",
    "Ultimately, all that MIRaGe needs to successfully simulate these images with different PSFs is an ordered list of the 18 PSF paths. There are a number of ways you could do that, but here we choose to:\n",
    "- generate a nested directory structure that matches the program structure\n",
    "- save each PSF into the corresponding directory (i.e. `Observation001/Visit002/Activity03/PSFLibrary.fits`)\n",
    "- provide MIRaGe with an ordered list of each PSF path, i.e.:\n",
    "       [Observation001/Visit001/Activity01/', 'Observation001/Visit001/Activity02/', ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dictionary that mirrors the program structure\n",
    "program_structure = {}\n",
    "for i in range(n_exposures):\n",
    "    obs_num = pointing_tab['obs_num'][i]\n",
    "    visit_num = pointing_tab['visit_num'][i]\n",
    "    activity_id = pointing_tab['act_id'][i]\n",
    "    \n",
    "    obs_key = 'Observation{}'.format(obs_num)\n",
    "    visit_key = 'Visit{}'.format(visit_num)\n",
    "    \n",
    "    program_structure.setdefault(obs_key, {})\n",
    "    visit_dict = program_structure[obs_key].setdefault(visit_key, []).append('Activity{}'.format(activity_id))                                                                      \n",
    "    \n",
    "pprint.pprint(program_structure)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create directory structure based on dictionary\n",
    "\n",
    "psf_paths = []\n",
    "program_dir = os.path.join(library_dir, root)\n",
    "for observation in program_structure.keys():\n",
    "    for visit in program_structure[observation].keys():\n",
    "        for activity in program_structure[observation][visit]:\n",
    "            activity_dir = os.path.join(program_dir, observation, visit, activity)\n",
    "            if not os.path.exists(activity_dir):\n",
    "                os.makedirs(activity_dir)\n",
    "            psf_paths.append(activity_dir)\n",
    "            \n",
    "pprint.pprint(glob(program_dir + '/**/', recursive=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adjustable_ote'></a>\n",
    "### Option 1: Use `webbpsf.enable_adjustable_ote()` to make a different PSF for each exposure\n",
    "\n",
    "In this case, we use `webbpsf` to **simulate different PSFs from a defined mirror state**, and we create 18 PSFs - **one for each exposure**.\n",
    "\n",
    "We will start with a image array (downgrading from large to medium for computational time), not yet coarsely phased. Then, we will bring one mirror segment in at a time for each of the 18 exposures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate starting PSF: a large image array with random pistons.\n",
    "nc = webbpsf.NIRCam()\n",
    "nc, ote = webbpsf.enable_adjustable_ote(nc)\n",
    "\n",
    "# Set up the array\n",
    "webbpsf.opds.setup_image_array(ote, reset=True, verbose=False, size='medium')\n",
    "\n",
    "# Add random pistons\n",
    "random_pistons = np.random.randn(18)*200  # substantial coarse phasing erorrs. \n",
    "for i, seg in enumerate(ote.segnames[0:18]):  # don't piston \"segment 19\" the SM\n",
    "    ote.move_seg_local(seg, piston=random_pistons[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fov_pixels = 1024\n",
    "original_psf = nc.calc_psf(monochromatic=2e-6, oversample=1, fov_pixels=fov_pixels)\n",
    "\n",
    "plt.imshow(original_psf[1].data, norm=LogNorm(), clim=(1e-10, 1e-5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mirror moves to bring the segments back in\n",
    "tilt_correction = []\n",
    "for i, segment in enumerate(ote.segment_state):\n",
    "    xtilt = segment[0]\n",
    "    ytilt = segment[1]\n",
    "    tilt_correction.append((i, -xtilt, -ytilt))\n",
    "pprint.pprint(tilt_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_psf_lib_for_ote(i):\n",
    "    start_time = time.time()\n",
    "    obs = 'Observation{}'.format(pointing_tab['obs_num'][i])\n",
    "    visit = 'Visit{}'.format(pointing_tab['visit_num'][i])\n",
    "    visit_dir = os.path.join(program_dir, obs, visit)\n",
    "    \n",
    "    print('Calculating PSF for obs {}, visit {}, exposure {}'\n",
    "          .format(pointing_tab['obs_num'][i], pointing_tab['visit_num'][i], i + 1))\n",
    "\n",
    "    i_seg, x_tilt_corr, y_tilt_corr = tilt_correction[i]\n",
    "    ote.move_seg_local(ote.segnames[i_seg], xtilt=x_tilt_corr, ytilt=y_tilt_corr)\n",
    "    nc.pupil = ote\n",
    "    \n",
    "    # Define the filter\n",
    "    nc.filter = 'F212N'\n",
    "    nc.detector = 'NRCA3'\n",
    "    \n",
    "    # Write out file\n",
    "    filename = 'nircam_fovp{}_samp1_npsf1.fits'.format(fov_pixels)\n",
    "    outfile = os.path.abspath(os.path.join(visit_dir, filename))\n",
    "    print(outfile)\n",
    "\n",
    "    # Generate the PSF grid\n",
    "    grid = nc.psf_grid(num_psfs=1, save=True, all_detectors=False,\n",
    "                           use_detsampled_psf=True, fov_pixels=fov_pixels,\n",
    "                            oversample=1, outfile=outfile)\n",
    "    \n",
    "    print('Elapsed time: {}\\n'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> <br>\n",
    "\n",
    "The for loop below will take a while: about 20 seconds for a 1024x1024 array, per detector, per filter! We've written it so that it will only write out for NIRCam A3 with the F212N filter, but even that will take about 5 minutes to complete 18 exposures. If you need to generate more PSFs for different telescope states, detectors, and filters, be aware that it might even take hours.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_exposures):\n",
    "    create_psf_lib_for_ote(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='to_model'></a>\n",
    "### Option 2: Use pre-existing FITS file as PSF for each visit\n",
    "\n",
    "In this case, we simply copy pre-existing FITS files into the program directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: you must have access to the STScI central storage directories to use this data.\n",
    "psf_fits_data_dir = '/grp/jwst/ote/mirage_example_data/'\n",
    "all_ote17_fits = sorted(glob(psf_fits_data_dir + '*.fits'))\n",
    "all_ote17_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for fun, plot all the data\n",
    "fig, axes = plt.subplots(3, 6, figsize=(15, 8))\n",
    "plt.tight_layout()\n",
    "\n",
    "i = 1\n",
    "for ax, f in zip(axes.flatten(), all_ote17_fits):\n",
    "    with fits.open(f) as hdulist:\n",
    "        psf_data = hdulist[1].data\n",
    "    ax.imshow(psf_data, clim=(0.1, 100))\n",
    "    ax.set_title('Exposure {}'.format(i))\n",
    "    i += 1\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Copy the images into the observation/visit/activity-specific directories\n",
    "for psf_path, fits_file in zip(psf_paths, all_ote17_fits):\n",
    "    shutil.copy(fits_file, psf_path)\n",
    "    print('Copied PSF to: {}'.format(os.path.abspath(os.path.join(psf_path, os.path.basename(fits_file)))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='make_yamls'></a>\n",
    "# 3. Create YAML files for each exposure\n",
    "\n",
    "Next, we need to make the YAML files that include all of the parameters for MIRaGe to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query online catalogs to generate catalog files of sources in FOV\n",
    "\n",
    "Next, we need to generate catalog files for the sources around the target in this proposal. First we must parse the `.pointing` file to determine the RA and Dec of the target (or targets) that will be observed. Then we will query 2MASS and WISE to get the magnitudes and locations of shortwave and longwave sources, respectively, around the target.\n",
    "\n",
    "All of this can be accomplished with the `mirage.get_catalog.get_all_catalogs` function.\n",
    "\n",
    "These catalog files will be written to your local `mirage/catalogs/` directory. If files for a given catalog and RA/Dec have already been generated, they will not be regenerated.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Important:</b> <br>\n",
    "\n",
    "Querying 2MASS and WISE is only appropriate for observations with the F212N and F480M NIRCam filters. If you want to simulate observations that use other filters, you will have to either query different bandpasses or catalogs or perform a photometric conversion on an existing catalog.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SW and LW catalogs\n",
    "cats = get_catalog.get_all_catalogs(pointing_file, prop_id)\n",
    "target_coords, catalog_filenames_sw, catalog_filenames_lw = cats\n",
    "\n",
    "cat_dict = {'nircam': {'lw': catalog_filenames_lw,\n",
    "                       'sw': catalog_filenames_sw}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the `.yaml` files\n",
    "\n",
    "Use `mirage.yaml.yaml_generator` to make all of the YAML files for the given APT program - one file per exposure.\n",
    "\n",
    "**Some additional settings are required to ensure `yaml_generator` works for nonnominal PSF simulations.** You must specify these attribute before running `create_inputs()` to make the YAMLs, and thus simulations, correctly:\n",
    "- `yam.add_psf_wings = False` - tells MIRaGe not to add wings to the PSF (we don't care since our PSFs are so big and sloppy anyway)\n",
    "<br><br>\n",
    "- `yam.psf_paths = [list or str]` - tells MIRaGe to use files in the given directory/directories for the PSFs paths for different exposures. `psf_paths` can be defined as:\n",
    "    - **A string pointing to a directory** - the matching PSF library in that directory will be written into ALL YAMLs, and thus will be used for ALL exposures in the program\n",
    "    - **A list of strings pointing to a list of directories** - Each directory in the list will be mapped onto the corresponding YAML (in alphanumeric order), and thus each exposure will be simulated using their respective, potentally different, PSF library. The list must be the same length as the number of exposures in the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a series of data simulator input yaml files from APT files\n",
    "# (Within this, create the observation table.)\n",
    "yaml_dir = os.path.join(out_dir, 'yamls')\n",
    "yam = yaml_generator.SimInput(input_xml=xml_file, pointing_file=pointing_file,\n",
    "                              catalogs=cat_dict,\n",
    "                              verbose=True, output_dir=yaml_dir, simdata_output_dir=out_dir)\n",
    "yam.psf_paths = psf_paths\n",
    "yam.add_psf_wings = False\n",
    "yam.create_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's examine where the sources will fall in an example exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine target pointings relative to apertures and V2/V3 references\n",
    "\n",
    "Looking at the `.pointing` file, let's plot where the target will appear relative to the NIRCam apertures for each unique pointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Examine apertures and V2/V3 references for each array/subarray\n",
    "nc_siaf = pysiaf.Siaf('NIRCam')\n",
    "nc_full = nc_siaf['NRCA1_FULL']\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for apername in sorted(nc_siaf.apernames):\n",
    "    a = apername\n",
    "    if ('_FULL' in a) and ('OSS' not in a) and ('MASK' not in a) and (a[-1] != 'P'):\n",
    "        nc_siaf[a].plot(frame='tel', name_label=a, fill_color='white')\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "# Compare V2/V3 of targets (from .pointing file)\n",
    "all_pointings = set([(v2, v3, filename) for v2, v3, filename in zip(yam.info['v2'], \n",
    "                                                                yam.info['v3'], \n",
    "                                                                yam.info['yamlfile'])])\n",
    "\n",
    "print('Example files for each pointing:')\n",
    "print('--------------------------------')\n",
    "plotted_points = []\n",
    "for i_point, (v2, v3, filename) in enumerate(all_pointings):\n",
    "    if (v2, v3) not in plotted_points:\n",
    "        plotted_points.append((v2, v3))\n",
    "        plt.scatter(v2, v3, marker='*', s=500, \n",
    "                    label='Pointing {}/{}'.format(i_point + 1, len(all_pointings)))\n",
    "        print('{}. {}'.format(i_point + 1, filename))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIRaGE can only generate one simulated exposure at a time, so even though we have many yaml files in our `yamls` directory, we need to choose just one to produce an image (see [Appendix 1](#simulate_whole_obs) for how to simulate multiple exposures at once). Not every exposure has the same pointing, so we should choose an exposure that places the target star in the desired detector FOV.\n",
    "\n",
    "This is easy for 1153 Obs. 1, since all 18 exposures do have the same pointing. We'll just choose a YAML that has a detector and filter that matches the library files we have created so far - NRCA3 and F212N.\n",
    "\n",
    "> Note: as described on [JDox](https://jwst-docs.stsci.edu/display/JDAT/File+Naming+Conventions+and+Data+Products), the yaml files are named like so:<br><br>\n",
    "> `jw<PPPPP><OOO><VVV>_<GGSAA>_<EEEEE>_<detector>.yaml`<br><br>\n",
    "> where:\n",
    "> * P = proposal number\n",
    "> * O = observation number\n",
    "> * V = visit number\n",
    "> * G = Visit Group\n",
    "> * S = Parallel Sequence id (1 prime, 2-5 parallel)\n",
    "> * A = Activity number (base 36)\n",
    "> * E = exposure number\n",
    "> \n",
    "> So `jw01140005001_0112n_00001_nrca3.yaml` would be the first visit in the fifth observation of APT proposal 1140, exposure 1, taken with the A3 detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yfiles = glob(os.path.join(yaml_dir, '*.yaml'))\n",
    "file_name_to_match = 'jw01153001001_01101_00001_nrca3'\n",
    "yaml_to_sim = os.path.abspath([y for y in yfiles if file_name_to_match in y][0])\n",
    "print(yaml_to_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='simulate_images'></a>\n",
    "# 4. Simulate image with MIRaGe\n",
    "\n",
    "Finally, we can run MIRaGe to generate a seed image simulation of our unstacked mirror state during OTE-01.\n",
    "\n",
    "From here on out, from the user perspective, the simulation process is identical for nominal imaging cases (see the [imaging example notebook](#Imaging_simulator_use_examples.ipynb). The specifications made in the YAML files are what enable the specialized behavior needed to simulate unstacked mirror simulations with MIRaGe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yaml_to_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_sim = imaging_simulator.ImgSim()\n",
    "img_sim.paramfile = yaml_to_sim\n",
    "img_sim.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2, ax3] = plt.subplots(1, 3, figsize=(20, 7))\n",
    "plt.tight_layout()\n",
    "\n",
    "clim = (5e8, 5e9)\n",
    "\n",
    "fitsplot = ax1.imshow(img_sim.seedimage, clim=clim, norm=LogNorm())\n",
    "ax1.set_title('Seed Image', size=24)\n",
    "ax1.invert_xaxis()\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "ax2.imshow(img_sim.linDark.data[0,-1,:,:] - img_sim.linDark.data[0,0,:,:], \n",
    "           clim=clim, norm=LogNorm())\n",
    "ax2.set_title('Dark Current', size=24)\n",
    "ax2.invert_xaxis()\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "linear_output = './nonnominal_psf_data/output/jw01153001001_01101_00001_nrca3_linear.fits'\n",
    "with fits.open(linear_output) as h:\n",
    "    lindata = h[1].data\n",
    "    header = h[0].header\n",
    "exptime = header['EFFINTTM']\n",
    "diffdata = (lindata[0,-1,:,:] - lindata[0,0,:,:]) / exptime\n",
    "\n",
    "ax3.imshow(diffdata, clim=clim, norm=LogNorm())\n",
    "ax3.set_title('Final Exposure Simulation', size=24)\n",
    "ax3.invert_xaxis()\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "# Define the colorbar\n",
    "cbar_ax = fig.add_axes([1, 0.09, 0.03, 0.87])\n",
    "cbar = plt.colorbar(fitsplot, cbar_ax)\n",
    "cbar.set_label('Count Rate', rotation=270, labelpad=30, size=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "---\n",
    "<a id='simulate_whole_obs'></a>\n",
    "# Appendix 1: Simulating many exposures at once\n",
    "\n",
    "Chances are, you don't want to simulate just one exposure from one detector. In order to simulate all of the exposures from a given observation, write a for loop to iterate over all the YAMLs. We include an example for program 1134 observation 1 below.\n",
    "\n",
    "### 1. Create all PSF library files\n",
    "First, make sure that you have created library files for all of the filters and detectors that will be simulated in your observation. (This might mean continuing [step 2](#create_psfs) above.)\n",
    "\n",
    "### 2. Run `imaging_simulator` for all YAMLs\n",
    "Second, grab all of the YAMLs for that specific observation and run the whole image simulator on them all.\n",
    "```python\n",
    "from mirage import imaging_simulator\n",
    "\n",
    "# Get all the 1134 Obs 1 NRCA3 yamls\n",
    "all_yaml_files = glob(ote_dir + 'jw01134001*.yaml')\n",
    "n_yamls = len(all_yaml_files)\n",
    "print('{} FITS files will be generated.'.format(n_yamls))\n",
    "\n",
    "for yaml in all_yaml_files:\n",
    "    print('*** SIMULATING YAML {}/{}: {} ***'.format(i+1, n_yamls, yaml))\n",
    "    img_sim = imaging_simulator.ImgSim()\n",
    "    img_sim.paramfile = yaml\n",
    "    img_sim.create()\n",
    "```\n",
    "\n",
    "(If you are impatient and ambitious, you can use Python's `multiprocessing` module to the simulation go faster. Even better on a server with more processors!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "---\n",
    "<a id='mosaic'></a>\n",
    "# Appendix 2: Combine into a mosaic\n",
    "\n",
    "### Turn linear FITS products into slope images\n",
    "```python\n",
    "obs1_fits = glob(os.path.join(ote_dir, 'jw*linear.fits'))\n",
    "print('{} FITS files produced for program APT 1134 Observation 1'.format(len(obs1_fits)))\n",
    "\n",
    "# Subtract the first from last for each ramp\n",
    "for f in obs1_fits:\n",
    "    with fits.open(f) as hdulist:\n",
    "        data = hdulist[1].data\n",
    "        hdr = hdulist[1].header\n",
    "        \n",
    "    diff = data[0, -1] - data[0, 0]\n",
    "\n",
    "    hdu = fits.PrimaryHDU(data=diff, header=hdr)\n",
    "\n",
    "    new_filename = os.path.join(ote_dir, 'slope_fits', os.path.basename(f))\n",
    "    hdu.writeto(new_filename, overwrite=True)\n",
    "    \n",
    "obs1_slope_fits = glob(os.path.join(ote_dir, 'slope_fits', 'jw*linear.fits'))\n",
    "```\n",
    "\n",
    "\n",
    "### Make ops file for QUIP\n",
    "```python\n",
    "# Set variables for writing QUIP ops file\n",
    "outdir = os.path.join(out_dir, 'quip')\n",
    "outfile = 'congrid'\n",
    "bindim = 2048\n",
    "opsfile = outdir+'ops_file_'+outfile.strip(\"/\")+str(bindim)+'.xml'\n",
    "\n",
    "# Write the file\n",
    "f = open(opsfile,'w')\n",
    "\n",
    "f.write('<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\\n')\n",
    "f.write('<QUIP_OPERATION_FILE xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" creator=\"WSS Executive\" time=\"16:22:40.093Z\" date=\"2017-06-14Z\" version=\"6.0.1\" operational=\"false\" xsi:noNamespaceSchemaLocation=\"/Users/lajoie/TEL/WSS-6.0.1/Software/schema/quip_operation_file.xsd\">\\n')\n",
    "f.write('    <CORRECTION_ID>R2017061401</CORRECTION_ID>\\n')\n",
    "f.write('    <OPERATION_TYPE>THUMBNAIL</OPERATION_TYPE>\\n')\n",
    "f.write('    <IMAGES>\\n')\n",
    "\n",
    "for filename in obs1_slope_fits:\n",
    "    f.write(\"       <IMAGE_PATH>{:s}</IMAGE_PATH>\\n\".format(filename))\n",
    "    \n",
    "f.write( '       </IMAGES>\\n'    )\n",
    "f.write( '       <OUTPUT>\\n')\n",
    "f.write( '           <OUTPUT_DIRECTORY>{:s}quip/</OUTPUT_DIRECTORY>\\n'.format(outdir))\n",
    "f.write( '           <LOG_FILE_PATH>{:s}quip/R2017061401_quip_activity_log.xml</LOG_FILE_PATH>\\n'.format(outdir))\n",
    "f.write( '           <OUT_FILE_PATH>{:s}quip/R2017061401_quip_out.xml</OUT_FILE_PATH>\\n'.format(outdir))\n",
    "f.write( '       </OUTPUT>\\n')\n",
    "\n",
    "f.write('</QUIP_OPERATION_FILE>\\n')\n",
    "\n",
    "f.close()\n",
    "\n",
    "print('Successfully wrote QUIP ops file to', opsfile)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
