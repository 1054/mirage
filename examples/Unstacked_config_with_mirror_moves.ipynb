{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Images with Unstacked PSFs and Mirror Moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a significant part of the JWST commissioning process (until around MIMF-3, expected L+118 days), the JWST OTE will not be optimally aligned. The mirrors will be unstacked and unphased, and thus the nominal JWST PSFs that MIRaGe uses when creating imaging simulations do not adequately represent this type of telescope state.\n",
    "\n",
    "In particular, this notebook can be used to simulate __OTE-03__, __OTE-04__, and __OTE-06__ activities.\n",
    "\n",
    "In this notebook, we demonstrate how to use MIRaGe to simulate early commissioning images using unstacked PSFs. The process is as follows:\n",
    "- Parse APT output files to access the details and structure of a given program.\n",
    "- Generate PSF libraries for the desired mirror state for each visit/exposure in a given observation, using `webbpsf` or existing FITS files. There should be N+1 PSF libraries, where N is the number of groups of mirror moves.\n",
    "- Generate MIRaGe YAML input files that include the directory in which to find the the nonnominal PSF libraries.\n",
    "- Generate seed images from those YAML files that use the appropriate PSF library for the desired exposures. Follow the nominal procedures for adding dark exposure and detector effects.\n",
    "\n",
    "### Table of Contents:\n",
    "1. [Export program information from APT](#export_apt)\n",
    "2. [Create diverse PSF library files](#create_psfs)\n",
    "3. [Create `.yaml` files for each exposure](#make_yamls)\n",
    "4. [Generate the simulated image](#simulate_images)\n",
    "\n",
    "Appendix A: [Generating data for an entire observation](#simulate_whole_obs)\n",
    "\n",
    "Appendix B: [Combining data into a mosaic](#mosaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "from glob import glob\n",
    "import os\n",
    "import pprint\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# Third Party Imports\n",
    "from astropy.io import fits\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pysiaf\n",
    "import webbpsf\n",
    "\n",
    "# Local Imports (from nircam_simulator package)\n",
    "from mirage import imaging_simulator\n",
    "from mirage.apt import apt_inputs, read_apt_xml\n",
    "from mirage.catalogs import get_catalog\n",
    "from mirage.utils.utils import ensure_dir_exists\n",
    "from mirage.yaml import yaml_generator\n",
    "\n",
    "from mirage.psf import psf_selection, deployments, segment_psfs\n",
    "\n",
    "import jwxml\n",
    "\n",
    "# View matplotlib plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='export_apt'></a>\n",
    "# 1. Export Program Information from APT\n",
    "\n",
    "MIRaGe requires APT program output files in order to generate data with nonnominal PSFs.\n",
    "\n",
    "### Get needed files from APT program\n",
    "\n",
    "Open the APT file for the program you want to simulate. If you don't have the file locally, you can load this program in APT by selecting `File > Retrieve from STScI > Retrieve Using Proposal ID` and then entering the program ID (e.g. 1140). (You must be running APT in STScI mode for this retrieval method to be available.)\n",
    "\n",
    "Export the `.pointing` and `.xml` files for your given proposal in APT by selecting `File > Export...` and selecting both the xml and pointing file options.\n",
    "\n",
    "For this example, we will simulate images from OTE-17: Image Stacking 2. In this stage of commissioning, the 18 mirror segments are being moved to transition from a hexagonal image array to 17 stacked segments with one kicked out. We will only look at observation 1, for brevity's sake. The neccessary files, `OTE17-1153-obs1only.pointing` and `OTE17-1153-obs1only.xml`, are located within the `examples/nonnominal_psf_data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the proposal ID\n",
    "prop_id = 1136\n",
    "OTEnumber = 'OTE03'\n",
    "\n",
    "# Where the pointing and XML file for this particular OTE CAR are located\n",
    "input_dir = './unstacked_with_mirror_moves/'\n",
    "\n",
    "# Change the root if you named your files differently.\n",
    "root = '{}-{}'.format(OTEnumber, prop_id)\n",
    "\n",
    "\n",
    "pointing_file = os.path.join(input_dir, '{}.pointing'.format(root))\n",
    "xml_file = os.path.join(input_dir, '{}.xml'.format(root))\n",
    "\n",
    "xml = read_apt_xml.ReadAPTXML()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define location of output files\n",
    "\n",
    "The process of generating simulated images with MIRaGe produces a lot of files:\n",
    "- YAML files carrying the OTE mirror state\n",
    "- YAML files carrying the specifications for simulations\n",
    "- FITS files of the simulated seed, dark, and compiled images\n",
    "\n",
    "Additionally, we must create FITS library files of the segment PSF images in order to simulate images with nonnominal PSFs.\n",
    "\n",
    "Let's define the directories to save these output files to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Where to save MIRaGe output\n",
    "out_dir = './unstacked_with_mirror_moves/output/'\n",
    "\n",
    "# Where the segment PSF library files will be saved to (and later read from)\n",
    "library_dir = os.path.join(out_dir, 'gridded_psf_library')\n",
    "\n",
    "# Make sure both these directories exist\n",
    "for full_path in [out_dir, library_dir]:\n",
    "    ensure_dir_exists(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the `.pointing` file to get the number of PSF libraries needed\n",
    "\n",
    "As mentioned above, we'll use the infrastructure of observation 1 in OTE-17: Image Stacking 2 (program 1153) for this example. \n",
    "\n",
    "This observation is a WFSC Commissioning observation that includes 17 Wavefront Control (WFC) groups to bring the mirrors in. (17 sets of image-mirror move-image plus 1 additional image.)\n",
    "\n",
    "So, in order to generate the YAML configuration files for program 1153 observation 1, MIRaGe will need 18 different PSF libraries representing the 18 different mirror states across OTE-17 Observation 1. \n",
    "\n",
    "We can parse the `.pointing` file to verify this number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the information from the pointing file\n",
    "apt_prop = apt_inputs.AptInput()\n",
    "pointing_tab = apt_prop.get_pointing_info(pointing_file, str(prop_id))\n",
    "n_exposures = len(pointing_tab['visit_id'])\n",
    "print('MIRaGe requires PSFs for {} exposures.'.format(len(pointing_tab['visit_id'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='create_psfs'></a>\n",
    "# 2. Create unique, nonnominal PSF library files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will outline two methods you can use to create an image with MIRaGe using unique PSFs for each exposure:\n",
    "- If you have a list of **mirror moves/positions** describing different telescope states throughout different observations/visits, use [option 1](#adjustable_ote). We will use `webbpsf` to generate PSFs and then gridded PSF library objects from those telescope states.\n",
    "- If you have a list of pre-existing **FITS files** with PSFs from different telescope states throughout different observations/visits, use [option 2](#to_model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Organizing PSF files\n",
    "\n",
    "For every exposure simulation, MIRaGe will use the PSF library defined by the `psf_path` argument of that exposure's YAML file. So, to create a MIRaGe simulation with a nonnominal PSF, you must provide a path other than the default to the `psf_path` argument.\n",
    "\n",
    "Thus, the easiest way to specify 18 different PSFs to be used for 18 different exposures is to:\n",
    "1. Save each unique PSF library in a different directory\n",
    "2. Pass an ordered list of the 18 separate directories to the YAML generator\n",
    "\n",
    "There are a number of ways you could do the first step above, but here we choose to:\n",
    "1. Generate a nested directory structure that matches the program structure\n",
    "2. Save each PSF into the corresponding directory (i.e. `Observation001/Visit002/Activity03/PSFLibrary.fits`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary that mirrors the program structure\n",
    "program_structure = {}\n",
    "\n",
    "iexp = 0\n",
    "iobs = '001'\n",
    "istart = 0\n",
    "\n",
    "exp_per_obs = {}\n",
    "for i in range(n_exposures):\n",
    "    obs_num = pointing_tab['obs_num'][i]\n",
    "  \n",
    "    if obs_num == iobs:\n",
    "        iexp += 1\n",
    "    else:\n",
    "        istart = i\n",
    "        iobs = obs_num\n",
    "        iexp = 1\n",
    "        \n",
    "    exp_per_obs[\"{}\".format(iobs)] = {'nexp':iexp, 'first_exp':istart, 'last_exp': i}\n",
    "        \n",
    "    visit_num = pointing_tab['visit_num'][i]\n",
    "    activity_id = str(iexp).zfill(2)\n",
    "    obs_key = 'Observation{}'.format(obs_num)\n",
    "    visit_key = 'Visit{}'.format(visit_num)\n",
    "    \n",
    "    program_structure.setdefault(obs_key, {})\n",
    "    visit_dict = program_structure[obs_key].setdefault(visit_key, []).append('Activity{}'.format(activity_id))                                                                      \n",
    "    \n",
    "pprint.pprint(program_structure)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create directory structure based on dictionary\n",
    "psf_paths = []\n",
    "program_dir = os.path.join(library_dir, root)\n",
    "for iobs, observation in enumerate(program_structure.keys()):\n",
    "    for visit in program_structure[observation].keys():\n",
    "        for activity in program_structure[observation][visit]:\n",
    "            activity_dir = os.path.join(program_dir, observation, visit, activity)\n",
    "            ensure_dir_exists(activity_dir)\n",
    "            psf_paths.append(activity_dir)\n",
    "    \n",
    "#pprint.pprint(glob(program_dir + '/**/', recursive=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adjustable_ote'></a>\n",
    "### 2.2: Use `webbpsf.enable_adjustable_ote()` to make a different PSF for each exposure\n",
    "\n",
    "In this case, we use `webbpsf` to simulate 18 PSFs, 1 for each exposure, each of which have their own unique mirror state.\n",
    "\n",
    "We will start with a image array (downgrading from large to medium for computational time), not yet coarsely phased. Then, we will bring one mirror segment in at a time for each of the 18 exposures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load OTE state from YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example deployments file\n",
    "deployments_file = os.path.join(input_dir, 'deployment_errors_reduced_20200129_164125.yaml')\n",
    "print(deployments_file)\n",
    "\n",
    "ote, segment_tilts, ote_opd_with_tilts = deployments.load_ote_from_deployment_yaml(deployments_file, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display OTE state and tip/tilt vectors\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax1.imshow(ote_opd_with_tilts)\n",
    "ax1.set_title('OTE with tilts')\n",
    "ax2.imshow(ote.opd)\n",
    "ax2.set_title('OTE without tilts')\n",
    "plt.show()\n",
    "\n",
    "#ote.print_state()\n",
    "\n",
    "print()\n",
    "header_string = 'Segment Number |{:^11}|{:^11}'.format('X Tilt', 'Y Tilt')\n",
    "print(header_string)\n",
    "print('-' * len(header_string))\n",
    "for i, (x, y) in enumerate(segment_tilts):\n",
    "    i_segment = i + 1\n",
    "    segname = webbpsf.webbpsf_core.segname(i_segment)\n",
    "    print('{:^14} | {:9.6} | {:9.6}'.format(segname, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the individual images for each exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User inputs (SUR, boresight offset, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sur_file = os.path.join(input_dir, 'SUR-OTE03-1136-Obs1.xml')\n",
    "\n",
    "boresight_offset = None # [-10, -5] #list, XTILT/YTILT arcminutes\n",
    "\n",
    "my_filters = \"F480M\" #['F212N', 'F480M']\n",
    "\n",
    "my_detectors = \"NRCB5\" #'all' # or list of individual detectors, e.g. ['NRCA5', 'NRCB5']\n",
    "                       # ['NRCA1', 'NRCA2', 'NRCA3', 'NRCA4', 'NRCB1', 'NRCB2', 'NRCB3', 'NRCB4']\n",
    "\n",
    "jitter = 0.048 #None, or arcseconds, radial. E.g. = 0.009 is 9 mas\n",
    "    \n",
    "    \n",
    "# IN THE CASE OF OTE-03, OTE-04, and OTE-06, WE CAN'T GENERATE ALL THE PSF LIBRARIES\n",
    "# AT ONCE SINCE IT REQUIRES MULTIPLE SURs. WE RECOMMEND GENERATING ONE OBSERVATION\n",
    "# AT A TIME.\n",
    "\n",
    "# SELECT AN OBSERVATION FOR WHICH TO GENERATE THE PSF LIBRARIES\n",
    "\n",
    "obs = 1  #integer\n",
    "\n",
    "exposures = np.arange(exp_per_obs[\"{:03d}\".format(obs)]['first_exp'], \n",
    "                      exp_per_obs[\"{:03d}\".format(obs)]['last_exp']+1)\n",
    "    \n",
    "print(\"Will generate images for Obs {} in {} on {} detector(s)\".format(obs, my_filters, my_detectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> <br>\n",
    "\n",
    "The for loop below will take a while: about 5 seconds for a 1024x1024 array, per detector, per filter! Therefore, select your filter/detector combinations wisely and as needed.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through the exposures and WFC groups to creates the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segment_lookup = {\n",
    "        'A1': 0, 'A2': 1, 'A3': 2, 'A4': 3, 'A5': 4,\n",
    "        'A6': 5, 'B1': 6, 'C1': 7, 'B2': 8, 'C2': 9,\n",
    "        'B3': 10, 'C3': 11, 'B4': 12, 'C4': 13,\n",
    "        'B5': 14, 'C5': 15, 'B6': 16, 'C6': 17 }\n",
    "\n",
    "\n",
    "iseg = None\n",
    "for iwfc_grp, i_exp in enumerate(exposures):\n",
    "    psf_dir = psf_paths[i_exp]\n",
    "           \n",
    "    print('Calculating PSF for obs {}, visit {}, exposure {}'\n",
    "          .format(pointing_tab['obs_num'][i_exp], \n",
    "                  pointing_tab['visit_num'][i_exp], \n",
    "                  iwfc_grp + 1))\n",
    "\n",
    "    #Only Move mirrors after the first exposure (image-move-image...)\n",
    "    if iwfc_grp > 0:\n",
    "        print(\"   Moving mirrors, group\", iwfc_grp)\n",
    "        ote.move_sur(sur_file, group = iwfc_grp-1)\n",
    "    \n",
    "    # FOR OTE-04 or OTE-06 ONLY: only generate images for the segment that is being moved; \n",
    "    # the other images should be copied from the previous exposure\n",
    "    if (prop_id == 1137 or prop_id == 1140) and iwfc_grp > 0:\n",
    "        sur = jwxml.SUR(sur_file)\n",
    "\n",
    "        group = iwfc_grp-1\n",
    "        if group is not None:\n",
    "            groups = [sur.groups[group]]\n",
    "        else:\n",
    "            groups = sur.groups\n",
    "            \n",
    "        for grp in groups:\n",
    "            for update in grp:\n",
    "                iseg = segment_lookup[update.segment]\n",
    "                print(\"      Moving seg {} only\".format(update.segment))\n",
    "\n",
    "                segment_tilts[iseg, 0] += ote.segment_state[iseg, 0]\n",
    "                segment_tilts[iseg, 1] += ote.segment_state[iseg, 1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Create PSF libraries\n",
    "    segment_psfs.generate_segment_psfs(ote, segment_tilts, psf_dir, \n",
    "                                       filters= my_filters, detectors=my_detectors, \n",
    "                                       overwrite=True, boresight=boresight_offset, segment=iseg,\n",
    "                                       jitter = jitter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OTE-04/OTE-06 Specifics (to minimize time generating images)\n",
    "\n",
    "Copy all the files from the previous exposure (n-1) into the current exposure, but DO NOT overwrite existing files. \n",
    "\n",
    "This assumes that the folders are empty except for the particular segment being moved in the exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prop_id == 1137 or prop_id == 1140:\n",
    "    maindir = os.path.join(library_dir, root, 'Observation{:03d}/Visit001'.format(obs))\n",
    "\n",
    "    directories = sorted(glob(maindir+\"/Activity*\"))\n",
    "    # Recursively copy files into exposure folders\n",
    "    for i, idir in enumerate(directories[:-1]):\n",
    "        orig_files = sorted(glob(idir+\"/*\"))\n",
    "        orig_files = [n.split(\"/\")[-1] for n in orig_files]\n",
    "        \n",
    "        for ifile in orig_files:\n",
    "            dest_files = sorted(glob(directories[i+1]+\"/*\"))\n",
    "            dest_files = [n.split(\"/\")[-1] for n in dest_files]\n",
    "\n",
    "            if ifile not in dest_files:\n",
    "                shutil.copy(idir+\"/\"+ifile, directories[i+1])\n",
    "\n",
    "    print('Files copied over the correct folders')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='make_yamls'></a>\n",
    "# 3. Create YAML files for each exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to make the YAML files that include all of the parameters for MIRaGe to run.\n",
    "\n",
    "Here we will provide the MIRaGe YAML generator with an ordered list of each PSF path we filled above, i.e.: \n",
    "\n",
    "    [Observation001/Visit001/Activity01/', 'Observation001/Visit001/Activity02/', ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query online catalogs to generate catalog files of sources around the target star\n",
    "\n",
    "Next, we need to generate catalog files containing RA, Dec, and magnitude for the sources around the target (or targets) in this proposal. \n",
    "\n",
    "First we must parse the `.pointing` file to determine the RA and Dec of the target (or targets) that will be observed. Then we will query the appropriate star catalogs to get the magnitudes and locations of shortwave and longwave sources, respectively, around the target(s). If you are using F212N and F480M NIRCam filters, you can use the 2MASS and WISE catalogs, respectively. If you are using one of these two filters, all of this can be accomplished with the `mirage.get_catalog.get_all_catalogs` function.  \n",
    "\n",
    "If different observations within the proposal have different targets, separate catalogs will be made for each target.\n",
    "\n",
    "These catalog files will be written to your local `mirage/catalogs/` directory. If files for a given catalog and RA/Dec have already been generated, they will not be regenerated.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Important:</b> <br>\n",
    "\n",
    "Querying 2MASS and WISE is only appropriate for observations with the F212N and F480M NIRCam filters. If you want to simulate observations that use other filters, you will have to either query different bandpasses or catalogs or perform a photometric conversion on an existing catalog.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save individual catalogs for the target areas\n",
    "catalog_dir = os.path.abspath(os.path.join(out_dir, 'catalogs'))\n",
    "cats = get_catalog.get_all_catalogs(xml_file, out_dir=catalog_dir)\n",
    "targets, target_coords, catalog_filenames = cats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate dictionary to be used for placing the proper catalog within each\n",
    "# yaml file\n",
    "catalog_inputs = {}\n",
    "for targ, cat in zip(targets, catalog_filenames):\n",
    "    catalog_inputs[targ] = {'point_source': cat}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the `.yaml` files\n",
    "\n",
    "MIRaGe's YAML generator,`mirage.yaml.yaml_generator`, will create all of the YAML files for a whole APT program at once - one YAML file per exposure in the program.\n",
    "\n",
    "**Some additional settings are required to ensure `yaml_generator` works for nonnominal PSF simulations.** You must specify theses attribute before running `create_inputs()` to make the YAML files correctly:\n",
    "- `yam.psf_paths = [list or str]` - tells MIRaGe to use files in the given directory/directories for the PSFs paths for different exposures. `psf_paths` can be defined as:\n",
    "    - *A string pointing to a directory* - the matching PSF library in that directory will be written into ALL YAMLs, and thus will be used for ALL exposures in the program\n",
    "    - *A list of strings pointing to a list of directories* - Each directory in the list will be mapped onto the corresponding YAML, in chronological order: the 0th listed directory will be used for the 0th exposure/YAML, the 1st listed directory for the 1st exposure/YAML, and so on. Thus each exposure will be simulated using its respective, potentially different, PSF library. The list must be the same length as the number of exposures in the program.\n",
    "    <br><br>\n",
    "- `yam.add_psf_wings = False` - tells MIRaGe not to add wings to the PSF. We don't need wings in this case, since our PSFs are so large.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create all input YAML files (one per each exposure)\n",
    "yaml_dir = os.path.join(out_dir, 'yamls')\n",
    "yam = yaml_generator.SimInput(input_xml=xml_file, pointing_file=pointing_file,\n",
    "                              catalogs=catalog_inputs,\n",
    "                              verbose=True, output_dir=yaml_dir, simdata_output_dir=out_dir)\n",
    "\n",
    "yam.psf_paths = psf_paths\n",
    "yam.add_psf_wings = False\n",
    "yam.expand_catalog_for_segments = True\n",
    "\n",
    "yam.create_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Choose which exposure to simulate (or skip to Appendix A)\n",
    "\n",
    "Now that we've generated all of the needed YAML files, we need to choose one to simulate images with. MIRaGE can only generate one simulated exposure at a time, so we need to choose one YAML file in our `yamls` directory that we will use to produce an image. (See [Appendix A](#simulate_whole_obs) for how use a wrapper to simulate multiple exposures at once with MIRaGe.)\n",
    "\n",
    "Not every exposure necessarily has the same pointing, so we should choose an exposure that places the target star in the desired detector field-of-view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine target pointings relative to apertures and V2/V3 references\n",
    "\n",
    "Looking at the `.pointing` file, let's plot where the target will appear relative to the NIRCam apertures for each unique pointing.\n",
    "\n",
    "We'll also print out the first YAML in the exposure list for each pointing. In this case, this just means printing out the first YAML, since there is only one pointing across all the exposures. However, if you are plotting the pointings for an observation that contains more than one pointing, then another YAML file will be added to the \"Example files for each pointing:\" list, corresponding to the exposure when the pointing changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Examine apertures and V2/V3 references for each array/subarray\n",
    "nc_siaf = pysiaf.Siaf('NIRCam')\n",
    "nc_full = nc_siaf['NRCA1_FULL']\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for apername in sorted(nc_siaf.apernames):\n",
    "    a = apername\n",
    "    if ('_FULL' in a) and ('OSS' not in a) and ('MASK' not in a) and (a[-1] != 'P'):\n",
    "        nc_siaf[a].plot(frame='tel', label=a, fill_color='white')\n",
    "\n",
    "# Compare V2/V3 of targets (from .pointing file)\n",
    "all_pointings = set([(v2, v3, filename) for v2, v3, filename in zip(yam.info['v2'], \n",
    "                                                                yam.info['v3'], \n",
    "                                                                yam.info['yamlfile'])])\n",
    "\n",
    "print('Example files for each pointing:')\n",
    "print('--------------------------------')\n",
    "plotted_points = []\n",
    "for i_point, (v2, v3, filename) in enumerate(all_pointings):\n",
    "    if (v2, v3) not in plotted_points:\n",
    "        plotted_points.append((v2, v3))\n",
    "        plt.scatter(v2, v3, marker='*', s=500, \n",
    "                    label='Pointing {}/{}'.format(i_point + 1, len(all_pointings)))\n",
    "        print('{}. {}'.format(i_point + 1, filename))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is easy for 1153 Obs. 1, since all 18 exposures have the same pointing. We'll just choose a YAML that has a detector and filter that matches the library files we have created so far - NRCA3 and F212N.\n",
    "\n",
    "Let's choose `jw01153001001_01101_00001_nrca3.yaml`.\n",
    "\n",
    "*See [JDox](https://jwst-docs.stsci.edu/display/JDAT/File+Naming+Conventions+and+Data+Products) for a detailed explanation of the MIRaGE YAML file name format.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one YAML where the target will be in the field of view\n",
    "yfiles = glob(os.path.join(yaml_dir, '*.yaml'))\n",
    "file_name_to_match = 'jw01136001001_01101_00003_nrcb5'\n",
    "yaml_to_sim = os.path.abspath([y for y in yfiles if file_name_to_match in y][0])\n",
    "print(yaml_to_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='simulate_images'></a>\n",
    "# 5. Simulate image with MIRaGe\n",
    "\n",
    "Finally, we can run MIRaGe to generate a seed image simulation of our unstacked mirror state during OTE-17.\n",
    "\n",
    "From here on out, from the user perspective, the simulation process is identical to that of nominal imaging cases (see the [imaging example notebook](#Imaging_simulator_use_examples.ipynb). To reiterate, it is the specifications made in the YAML files that enable the simulation of nonnominal mirror simulations with MIRaGe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the image simulator using the input defined in yaml_to_sim\n",
    "img_sim = imaging_simulator.ImgSim()\n",
    "img_sim.paramfile = yaml_to_sim\n",
    "img_sim.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the seed image, dark image, and final exposure simulation\n",
    "fig, [ax1, ax2, ax3] = plt.subplots(1, 3, figsize=(20, 7))\n",
    "plt.tight_layout()\n",
    "\n",
    "# Define scale limits and colormap\n",
    "clim = (1e-2, 1e4)\n",
    "cmap = cm.get_cmap('viridis')\n",
    "cmap.set_bad(cmap(0))\n",
    "\n",
    "# Plot seed image\n",
    "fitsplot = ax1.imshow(img_sim.seedimage, clim=clim, norm=LogNorm(), cmap=cmap)\n",
    "ax1.set_title('Seed Image', size=24)\n",
    "\n",
    "# Plot dark current\n",
    "dark_diff = img_sim.linDark.data[0,-1,:,:] - img_sim.linDark.data[0,0,:,:]\n",
    "ax2.imshow(dark_diff, \n",
    "           clim=clim, norm=LogNorm())\n",
    "ax2.set_title('Dark Current', size=24)\n",
    "\n",
    "# Plot final exposure\n",
    "linear_output = './nonnominal_psf_data/output/jw01153001001_01101_00001_nrca3_linear.fits'\n",
    "with fits.open(linear_output) as h:\n",
    "    lindata = h[1].data\n",
    "    header = h[0].header\n",
    "exptime = header['EFFINTTM']\n",
    "diffdata = (lindata[0,-1,:,:] - lindata[0,0,:,:]) / exptime\n",
    "\n",
    "ax3.imshow(diffdata, clim=clim, norm=LogNorm())\n",
    "ax3.set_title('Final Exposure Simulation', size=24)\n",
    "\n",
    "# Define the colorbar\n",
    "cbar_ax = fig.add_axes([1, 0.09, 0.03, 0.87])\n",
    "cbar = plt.colorbar(fitsplot, cbar_ax)\n",
    "cbar.set_label('Count Rate', rotation=270, labelpad=30, size=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "---\n",
    "<a id='simulate_whole_obs'></a>\n",
    "# Appendix A: Simulating many exposures at once\n",
    "\n",
    "Chances are, you don't want to simulate just one exposure from one detector. In order to simulate all of the exposures from a given observation, write a for loop to iterate over all the YAMLs. We include an example for program 1134 observation 1 below.\n",
    "\n",
    "### 1. Create all PSF library files\n",
    "First, make sure that you have created library files for all of the filters and detectors that will be simulated in your observation. (This might mean continuing [step 2](#create_psfs) above.)\n",
    "\n",
    "### 2. Run `imaging_simulator` for a set of YAMLs\n",
    "Second, grab all of the desired YAMLs for that observation and run the image simulator on them all.\n",
    "\n",
    "(If you are impatient and ambitious, you can use Python's `multiprocessing` module to the simulation go faster. Even better on a server with more processors!)\n",
    "\n",
    "To learn how to combine multiple exposure simulations into a mosaic with QUIP, see [Appendix B](#mosaic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from mirage import imaging_simulator\n",
    "\n",
    "pid     = str(prop_id).zfill(5) \n",
    "channel = 'LW'\n",
    "\n",
    "if channel == 'LW':\n",
    "    all_yaml_files = glob(os.path.join(yaml_dir, 'jw{}{:03d}*b5.yaml'.format(pid, obs)))\n",
    "elif channel == 'SW':\n",
    "    all_yaml_files = glob(os.path.join(yaml_dir, 'jw{}{:03d}*[!5].yaml'.format(pid, obs)))\n",
    "else:\n",
    "    all_yaml_files = glob(os.path.join(yaml_dir, 'jw{}{:03d}*.yaml'.format(pid, obs)))\n",
    "\n",
    "    \n",
    "n_yamls = len(all_yaml_files)\n",
    "print('{} FITS files will be generated for {}.'.format(n_yamls, pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, yaml in enumerate(sorted(all_yaml_files)):\n",
    "    print('*** SIMULATING YAML {}/{}: {} ***'.format(i+1, n_yamls, yaml))\n",
    "\n",
    "    img_sim = imaging_simulator.ImgSim()\n",
    "    img_sim.paramfile = yaml\n",
    "    img_sim.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "---\n",
    "<a id='mosaic'></a>\n",
    "# Appendix B: Combine into a mosaic\n",
    "\n",
    "The [`wss_tools`](https://wss-tools.readthedocs.io/en/latest/) include a software program, QUIP, which can be used to combine a list of FITS files into a single mosaic image. QUIP requires an operations file, which we describe how to make here.\n",
    "\n",
    "### Turn linear FITS products into slope images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "from mirage.utils.utils import ensure_dir_exists\n",
    "\n",
    "obs1_fits = glob(os.path.join(out_dir, 'jw*linear.fits'))\n",
    "print('{} FITS files produced for program APT 1153 Observation 1'.format(len(obs1_fits)))\n",
    "\n",
    "# Subtract the first from last for each ramp\n",
    "for f in obs1_fits:\n",
    "    with fits.open(f) as hdulist:\n",
    "        data = hdulist[1].data\n",
    "        hdr = hdulist[1].header\n",
    "        \n",
    "    diff = data[0, -1] - data[0, 0]\n",
    "\n",
    "    hdu = fits.PrimaryHDU(data=diff, header=hdr)\n",
    "\n",
    "    new_filename = os.path.join(out_dir, 'slope_fits', os.path.basename(f))\n",
    "    ensure_dir_exists(os.path.dirname(new_filename))\n",
    "    hdu.writeto(new_filename, overwrite=True)\n",
    "    \n",
    "obs1_slope_fits = glob(os.path.join(out_dir, 'slope_fits', 'jw*linear.fits'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make ops file for QUIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for writing QUIP ops file\n",
    "quip_dir = os.path.join(out_dir, 'quip')\n",
    "ensure_dir_exists(quip_dir)\n",
    "outfile = 'congrid'\n",
    "bindim = 2048\n",
    "opsfile = os.path.join(quip_dir, 'ops_file_'+outfile.strip(\"/\")+str(bindim)+'.xml')\n",
    "\n",
    "# Write the file\n",
    "f = open(opsfile, 'w')\n",
    "\n",
    "f.write('<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\\n')\n",
    "f.write('<QUIP_OPERATION_FILE xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" creator=\"WSS Executive\" time=\"16:22:40.093Z\" date=\"2017-06-14Z\" version=\"6.0.1\" operational=\"false\" xsi:noNamespaceSchemaLocation=\"/Users/lajoie/TEL/WSS-6.0.1/Software/schema/quip_operation_file.xsd\">\\n')\n",
    "f.write('    <CORRECTION_ID>R2017061401</CORRECTION_ID>\\n')\n",
    "f.write('    <OPERATION_TYPE>THUMBNAIL</OPERATION_TYPE>\\n')\n",
    "f.write('    <IMAGES>\\n')\n",
    "\n",
    "for filename in obs1_slope_fits:\n",
    "    f.write(\"       <IMAGE_PATH>{:s}</IMAGE_PATH>\\n\".format(filename))\n",
    "\n",
    "f.write( '       </IMAGES>\\n'    )\n",
    "f.write( '       <OUTPUT>\\n')\n",
    "f.write( '           <OUTPUT_DIRECTORY>{:s}quip/</OUTPUT_DIRECTORY>\\n'.format(quip_dir))\n",
    "f.write( '           <LOG_FILE_PATH>{:s}quip/R2017061401_quip_activity_log.xml</LOG_FILE_PATH>\\n'.format(quip_dir))\n",
    "f.write( '           <OUT_FILE_PATH>{:s}quip/R2017061401_quip_out.xml</OUT_FILE_PATH>\\n'.format(quip_dir))\n",
    "f.write( '       </OUTPUT>\\n')\n",
    "\n",
    "f.write('</QUIP_OPERATION_FILE>\\n')\n",
    "\n",
    "f.close()\n",
    "\n",
    "print('Successfully wrote QUIP ops file to', opsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
